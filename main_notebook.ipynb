{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U_u9VSi2seE3"
      },
      "source": [
        "# **VISON+ - Enhanced Video Summarization**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_DtgkWSL70cp"
      },
      "source": [
        "Team Members:\n",
        "---\n",
        "- Balaji Bojadla\n",
        "- Mallikarjunarao Kovi\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5E8uhMibsWF2"
      },
      "source": [
        "\n",
        "# **Abstract**\n",
        "---\n",
        "Video summarization plays a crucial role in condensing lengthy videos into shorter versions while retaining key information. This project, titled VISON+ - Enhanced Video Summarization, aims to create comprehensive video summaries for long YouTube videos using both abstractive and extractive summarization techniques. By leveraging Natural Language Processing (NLP) pipelines and innovative video editing methods, VISON+ generates concise and informative summaries that capture the essence of the original content. This report outlines the methodology, techniques, and outcomes of the VISON+ project, along with a review of related work in the field of video summarization.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yUpvDpxd7_H7"
      },
      "source": [
        "\n",
        "# **Introduction**\n",
        "---\n",
        "Video content has become increasingly prevalent on online platforms such as YouTube, providing a vast repository of information and entertainment. However, the sheer volume of video content available poses challenges for viewers who may not have the time or patience to watch lengthy videos in their entirety. Video summarization addresses this challenge by condensing videos into shorter versions while preserving essential information.\n",
        "\n",
        "The project titled VISON+ - Enhanced Video Summarization aims to enhance the accessibility and usability of long YouTube videos by creating concise and informative video summaries. This project utilizes advanced techniques in abstractive and extractive summarization to generate comprehensive summaries that capture the essence of the original content. By combining these techniques with innovative video editing methods, VISON+ produces summary videos that offer quick insights into the content of lengthy videos.\n",
        "\n",
        "In this report, we present the methodology, techniques, and outcomes of the VISON+ project. We begin by discussing the data collection process and the tools used for video transcription. Next, we delve into the details of abstractive and extractive summarization techniques employed in the project. We also provide a review of related work in the field of video summarization, highlighting key contributions and methodologies from existing literature.\n",
        "\n",
        "Throughout the report, we use Markdown Cells to explain the outputs of our Code Cells, providing a clear and concise narrative of the project's methodology and outcomes. By leveraging advanced techniques in video summarization, VISON+ offers a novel approach to enhancing the accessibility and usability of long YouTube videos, paving the way for efficient consumption of video content in various domains."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JR4Pjtftr7GB"
      },
      "source": [
        "\n",
        "# **Literature Review**\n",
        "---\n",
        "**Literature Review**\n",
        "\n",
        "Video summarization is a critical task in multimedia content analysis, aimed at condensing lengthy videos into shorter versions while retaining key information. In recent years, various approaches and techniques have been developed to address this challenge. In this literature review, we explore related work in the field of video summarization, highlighting key contributions and methodologies.\n",
        "\n",
        "1. **YouTube Transcript API**  \n",
        "   The YouTube Transcript API, developed by Depoix [1], provides a convenient way to access and extract transcripts from YouTube videos. This tool facilitates the retrieval of textual content from videos, which is essential for subsequent analysis and summarization tasks.\n",
        "\n",
        "   [1] GitHub Repository: [https://github.com/jdepoix/youtube-transcript-api](https://github.com/jdepoix/youtube-transcript-api)\n",
        "\n",
        "2. **AI-Driven YouTube Video Generation**  \n",
        "   Oluyale [2] presents a comprehensive guide on generating YouTube videos using AI and machine learning techniques. The article discusses the use of NLP pipelines and summarization algorithms to generate concise and informative video content. This work provides insights into the application of AI in video content creation.\n",
        "\n",
        "   [2] Medium Article: [https://medium.com/@oluyaled/generate-youtube-video-using-ai-ml-python-c9ba9c86f9ea](https://medium.com/@oluyaled/generate-youtube-video-using-ai-ml-python-c9ba9c86f9ea)\n",
        "\n",
        "3. **Speech-to-Text Extraction from Video**  \n",
        "   GeeksforGeeks offers a tutorial on extracting speech-to-text from videos using Python [3]. This tutorial introduces techniques for converting audio content from videos into textual transcripts, which can be further analyzed and summarized using natural language processing algorithms.\n",
        "\n",
        "   [3] GeeksforGeeks Tutorial: [https://www.geeksforgeeks.org/extract-speech-text-from-video-in-python/](https://www.geeksforgeeks.org/extract-speech-text-from-video-in-python/)\n",
        "\n",
        "4. **Video Concatenation with MoviePy**  \n",
        "   The MoviePy library, as demonstrated by GeeksforGeeks [4], provides functionalities for concatenating multiple video files. This capability is crucial for assembling summary videos from segmented clips, allowing for the creation of concise and coherent video summaries.\n",
        "\n",
        "   [4] GeeksforGeeks Tutorial: [https://www.geeksforgeeks.org/moviepy-concatenating-multiple-video-files/](https://www.geeksforgeeks.org/moviepy-concatenating-multiple-video-files/)\n",
        "\n",
        "5. **Transformer-Based Text Summarization with Hugging Face**  \n",
        "   Hugging Face offers a suite of pre-trained transformer models fine-tuned for various NLP tasks, including text summarization [5]. These models leverage transformer architectures to generate concise summaries from textual input. The Hugging Face documentation provides comprehensive guidance on using these models for text summarization tasks.\n",
        "\n",
        "   [5] Hugging Face Summarization Documentation: [https://huggingface.co/docs/transformers/en/tasks/summarization](https://huggingface.co/docs/transformers/en/tasks/summarization)\n",
        "\n",
        "These references provide valuable insights and tools for the development and implementation of video summarization systems. By leveraging these resources and building upon existing methodologies, researchers and practitioners can continue to advance the field of multimedia content analysis and enhance the accessibility and usability of video content.\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JrM3VRzlCJgJ"
      },
      "source": [
        "**Training Procedure of Summarization Model**\n",
        "---\n",
        "The summarization model used in this project, \"sshleifer/distilbart-cnn-12-6\", is a pre-trained transformer model fine-tuned specifically for the task of text summarization. The training procedure for this model typically involves the following steps:\n",
        "\n",
        "1. **Data Collection:** The training data for the summarization model consists of a large corpus of text data, typically sourced from various sources such as news articles, blog posts, academic papers, and other publicly available textual content. The dataset should include pairs of input text and their corresponding summaries.\n",
        "\n",
        "2. **Preprocessing:** Before training the model, the training data undergoes preprocessing steps to clean and prepare it for the summarization task. This may include removing irrelevant content, tokenizing the text into individual words or subwords, and converting the text into numerical representations suitable for input into the model.\n",
        "\n",
        "3. **Model Architecture:** The summarization model is based on transformer architecture, which is a type of neural network architecture known for its effectiveness in handling sequential data. Transformers consist of multiple layers of self-attention mechanisms and feed-forward neural networks, allowing them to capture dependencies between words in the input text and generate coherent summaries.\n",
        "\n",
        "4. **Fine-tuning:** The pre-trained transformer model is fine-tuned on the specific task of text summarization using the training data. During fine-tuning, the model adjusts its parameters to minimize a loss function that measures the difference between the generated summaries and the ground truth summaries in the training data.\n",
        "\n",
        "5. **Evaluation:** After fine-tuning, the model is evaluated on a separate validation set to assess its performance in generating accurate and coherent summaries. Evaluation metrics such as ROUGE (Recall-Oriented Understudy for Gisting Evaluation) scores are commonly used to measure the quality of the generated summaries compared to the ground truth.\n",
        "\n",
        "6. **Deployment:** Once the model has been trained and evaluated satisfactorily, it can be deployed for use in summarizing new input text data. The deployed model accepts input text and generates concise summaries based on the learned patterns and associations in the training data.\n",
        "\n",
        "The summarization model \"sshleifer/distilbart-cnn-12-6\" utilized in this project has been trained on the BillSum dataset, provided by Hugging Face. The BillSum dataset is a collection of legislative bills and their summaries, sourced from various state legislatures in the United States.\n",
        "\n",
        "**BillSum Dataset Description:**\n",
        "- The BillSum dataset consists of pairs of legislative bills and their corresponding summaries, providing concise representations of the main points and key information contained within each bill.\n",
        "- Each sample in the dataset contains the full text of a legislative bill, along with its associated summary, which is typically a shorter version of the bill's contents.\n",
        "- The dataset covers a wide range of topics and legislative domains, including healthcare, education, transportation, and more, reflecting the diversity of legislative activity across different states.\n",
        "- The dataset is well-annotated, with high-quality summaries that accurately capture the essential information and key provisions of each bill.\n",
        "\n",
        "**Dataset Link:**\n",
        "- [BillSum Dataset](https://huggingface.co/datasets/billsum)\n",
        "\n",
        "The BillSum dataset serves as a valuable resource for training summarization models, providing rich and diverse text data that can be used to develop and evaluate the effectiveness of text summarization algorithms. By leveraging the BillSum dataset, the \"sshleifer/distilbart-cnn-12-6\" model has been fine-tuned to generate high-quality summaries across a variety of legislative contexts, making it well-suited for summarizing text from a wide range of domains and topics."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wv5c5I_W0psW"
      },
      "source": [
        "**Data Collection:**\n",
        "---\n",
        "For the training of the Hugging Face model, we utilized a pre-existing dataset provided by Hugging Face called BillSum. The BillSum dataset contains pairs of legislative bills and their corresponding summaries, sourced from various state legislatures in the United States. This dataset serves as a valuable resource for training summarization models, providing rich and diverse text data suitable for the summarization task.\n",
        "\n",
        "**Data Cleaning:**\n",
        "---\n",
        "As the summarization model \"sshleifer/distilbart-cnn-12-6\" was pre-trained on the BillSum dataset, we did not perform explicit training in this project. Instead, we focused on preparing our data for inference with the pre-trained model. We obtained YouTube video transcripts using the YouTube Transcript API, which provided textual content from YouTube videos in the form of transcribed paragraphs.\n",
        "\n",
        "**Data Processing:**\n",
        "---\n",
        "After obtaining the transcribed paragraph text from the YouTube videos, we processed the data to ensure compatibility with the summarization model and to prepare it for generating the final summary video.\n",
        "\n",
        "Firstly, we converted the transcribed paragraphs into individual sentences or segments, as required by the summarization model. Each sentence or segment served as an input to the model for generating summaries.\n",
        "\n",
        "Next, we filtered the transcribed list by deleting sentences that were not presented in the summary paragraph. This step ensured that only relevant content was considered for summarization, improving the quality and relevance of the generated summary.\n",
        "\n",
        "Finally, we refined the output list of dictionaries by removing unnecessary fields such as the 'text' field, which contained the transcribed text. Instead, we retained only the 'start' and 'duration' fields, which provided information about the timing of each segment in the video. These fields were essential for splitting and merging the video segments to create the final summary video.\n",
        "\n",
        "By processing the transcribed data in this manner, we ensured that it was compatible with the summarization model and suitable for generating concise and informative summaries. Additionally, refining the output list of dictionaries allowed for efficient manipulation of video segments to produce the final summary video.\n",
        "\n",
        "**Description of YouTube Video Input, Text Extraction, and Summary Paragraph Output:**\n",
        "---\n",
        "- **YouTube Video Input**: The YouTube videos served as the source of content for the summarization task. These videos covered a wide range of topics and genres, ensuring diversity in the training data. The YouTube Transcript API facilitated the extraction of textual content from the videos, providing transcribed paragraphs for summarization.\n",
        "\n",
        "- **Text Extraction**: The text extraction process involved retrieving transcribed paragraphs from the YouTube videos using the YouTube Transcript API. Each transcribed paragraph represented the textual content of the video, providing input data for the summarization model.\n",
        "\n",
        "- **Summary Paragraph Output**: The output of the summarization process was a summary paragraph containing key sentences extracted from the transcribed video content. This summary paragraph condensed the original video content into a concise and informative summary, capturing the essence of the video in a shorter form.\n",
        "\n",
        "In this project, since the summarization model \"sshleifer/distilbart-cnn-12-6\" was pre-trained on the BillSum dataset, we focused on processing the cleaned and processed video transcript data into our preferred format for inference with the pre-trained model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uj74D6ObO8c4",
        "outputId": "2444887e-64c0-409a-e755-eadcd512b382"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting youtube-transcript-api\n",
            "  Downloading youtube_transcript_api-0.6.2-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from youtube-transcript-api) (2.31.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->youtube-transcript-api) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->youtube-transcript-api) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->youtube-transcript-api) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->youtube-transcript-api) (2024.2.2)\n",
            "Installing collected packages: youtube-transcript-api\n",
            "Successfully installed youtube-transcript-api-0.6.2\n",
            "Collecting langdetect\n",
            "  Downloading langdetect-1.0.9.tar.gz (981 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m981.5/981.5 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from langdetect) (1.16.0)\n",
            "Building wheels for collected packages: langdetect\n",
            "  Building wheel for langdetect (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for langdetect: filename=langdetect-1.0.9-py3-none-any.whl size=993227 sha256=693e460db6c1b3c042f689c0bcc7fabacea2dab71b1a9032d59ba9f4e4575f51\n",
            "  Stored in directory: /root/.cache/pip/wheels/95/03/7d/59ea870c70ce4e5a370638b5462a7711ab78fba2f655d05106\n",
            "Successfully built langdetect\n",
            "Installing collected packages: langdetect\n",
            "Successfully installed langdetect-1.0.9\n",
            "Collecting pytube\n",
            "  Downloading pytube-15.0.0-py3-none-any.whl (57 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.6/57.6 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pytube\n",
            "Successfully installed pytube-15.0.0\n",
            "Requirement already satisfied: spacy in /usr/local/lib/python3.10/dist-packages (3.7.4)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (8.2.3)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.1.2)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (0.3.4)\n",
            "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (0.9.4)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy) (6.4.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (4.66.4)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.31.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.7.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.1.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy) (67.7.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (24.0)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.4.0)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.25.2)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.10/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.2.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.2 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.18.2)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.11.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2024.2.2)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.1.4)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.10.0,>=0.3.0->spacy) (8.1.7)\n",
            "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.4.0,>=0.1.0->spacy) (0.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy) (2.1.5)\n",
            "Requirement already satisfied: marisa-trie>=0.7.7 in /usr/local/lib/python3.10/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.1.1)\n",
            "Collecting en-core-web-lg==3.7.1\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_lg-3.7.1/en_core_web_lg-3.7.1-py3-none-any.whl (587.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m587.7/587.7 MB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy<3.8.0,>=3.7.2 in /usr/local/lib/python3.10/dist-packages (from en-core-web-lg==3.7.1) (3.7.4)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (8.2.3)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (1.1.2)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (0.3.4)\n",
            "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (0.9.4)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (6.4.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (4.66.4)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (2.31.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (2.7.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (3.1.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (67.7.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (24.0)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (3.4.0)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (1.25.2)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.10/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (1.2.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.2 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (2.18.2)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (4.11.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (2024.2.2)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (0.1.4)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.10.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (8.1.7)\n",
            "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.4.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (0.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (2.1.5)\n",
            "Requirement already satisfied: marisa-trie>=0.7.7 in /usr/local/lib/python3.10/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (1.1.1)\n",
            "Installing collected packages: en-core-web-lg\n",
            "Successfully installed en-core-web-lg-3.7.1\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_lg')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n",
            "Collecting pytextrank\n",
            "  Downloading pytextrank-3.3.0-py3-none-any.whl (26 kB)\n",
            "Collecting GitPython>=3.1 (from pytextrank)\n",
            "  Downloading GitPython-3.1.43-py3-none-any.whl (207 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.3/207.3 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: graphviz>=0.13 in /usr/local/lib/python3.10/dist-packages (from pytextrank) (0.20.3)\n",
            "Collecting icecream>=2.1 (from pytextrank)\n",
            "  Downloading icecream-2.1.3-py2.py3-none-any.whl (8.4 kB)\n",
            "Requirement already satisfied: networkx[default]>=2.6 in /usr/local/lib/python3.10/dist-packages (from pytextrank) (3.3)\n",
            "Requirement already satisfied: pygments>=2.7.4 in /usr/local/lib/python3.10/dist-packages (from pytextrank) (2.16.1)\n",
            "Requirement already satisfied: scipy>=1.7 in /usr/local/lib/python3.10/dist-packages (from pytextrank) (1.11.4)\n",
            "Requirement already satisfied: spacy>=3.0 in /usr/local/lib/python3.10/dist-packages (from pytextrank) (3.7.4)\n",
            "Collecting gitdb<5,>=4.0.1 (from GitPython>=3.1->pytextrank)\n",
            "  Downloading gitdb-4.0.11-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting colorama>=0.3.9 (from icecream>=2.1->pytextrank)\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Collecting executing>=0.3.1 (from icecream>=2.1->pytextrank)\n",
            "  Downloading executing-2.0.1-py2.py3-none-any.whl (24 kB)\n",
            "Collecting asttokens>=2.0.1 (from icecream>=2.1->pytextrank)\n",
            "  Downloading asttokens-2.4.1-py2.py3-none-any.whl (27 kB)\n",
            "Requirement already satisfied: numpy>=1.23 in /usr/local/lib/python3.10/dist-packages (from networkx[default]>=2.6->pytextrank) (1.25.2)\n",
            "Requirement already satisfied: matplotlib>=3.6 in /usr/local/lib/python3.10/dist-packages (from networkx[default]>=2.6->pytextrank) (3.7.1)\n",
            "Requirement already satisfied: pandas>=1.4 in /usr/local/lib/python3.10/dist-packages (from networkx[default]>=2.6->pytextrank) (2.0.3)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy>=3.0->pytextrank) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy>=3.0->pytextrank) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy>=3.0->pytextrank) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy>=3.0->pytextrank) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy>=3.0->pytextrank) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy>=3.0->pytextrank) (8.2.3)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy>=3.0->pytextrank) (1.1.2)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy>=3.0->pytextrank) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy>=3.0->pytextrank) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy>=3.0->pytextrank) (0.3.4)\n",
            "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy>=3.0->pytextrank) (0.9.4)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy>=3.0->pytextrank) (6.4.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy>=3.0->pytextrank) (4.66.4)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy>=3.0->pytextrank) (2.31.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy>=3.0->pytextrank) (2.7.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy>=3.0->pytextrank) (3.1.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy>=3.0->pytextrank) (67.7.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy>=3.0->pytextrank) (24.0)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy>=3.0->pytextrank) (3.4.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from asttokens>=2.0.1->icecream>=2.1->pytextrank) (1.16.0)\n",
            "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->GitPython>=3.1->pytextrank)\n",
            "  Downloading smmap-5.0.1-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.10/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy>=3.0->pytextrank) (1.2.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.6->networkx[default]>=2.6->pytextrank) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.6->networkx[default]>=2.6->pytextrank) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.6->networkx[default]>=2.6->pytextrank) (4.51.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.6->networkx[default]>=2.6->pytextrank) (1.4.5)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.6->networkx[default]>=2.6->pytextrank) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.6->networkx[default]>=2.6->pytextrank) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.6->networkx[default]>=2.6->pytextrank) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.4->networkx[default]>=2.6->pytextrank) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.4->networkx[default]>=2.6->pytextrank) (2024.1)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy>=3.0->pytextrank) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.2 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy>=3.0->pytextrank) (2.18.2)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy>=3.0->pytextrank) (4.11.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=3.0->pytextrank) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=3.0->pytextrank) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=3.0->pytextrank) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=3.0->pytextrank) (2024.2.2)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy>=3.0->pytextrank) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy>=3.0->pytextrank) (0.1.4)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.10.0,>=0.3.0->spacy>=3.0->pytextrank) (8.1.7)\n",
            "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.4.0,>=0.1.0->spacy>=3.0->pytextrank) (0.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy>=3.0->pytextrank) (2.1.5)\n",
            "Requirement already satisfied: marisa-trie>=0.7.7 in /usr/local/lib/python3.10/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy>=3.0->pytextrank) (1.1.1)\n",
            "Installing collected packages: smmap, executing, colorama, asttokens, icecream, gitdb, GitPython, pytextrank\n",
            "Successfully installed GitPython-3.1.43 asttokens-2.4.1 colorama-0.4.6 executing-2.0.1 gitdb-4.0.11 icecream-2.1.3 pytextrank-3.3.0 smmap-5.0.1\n"
          ]
        }
      ],
      "source": [
        "!pip install youtube-transcript-api\n",
        "!pip install langdetect\n",
        "!pip install pytube\n",
        "!pip install spacy\n",
        "!python3 -m spacy download en_core_web_lg\n",
        "!pip install pytextrank"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8ItcIj1pS5ui"
      },
      "outputs": [],
      "source": [
        "# Import all the necessary dependencies\n",
        "from youtube_transcript_api import YouTubeTranscriptApi\n",
        "from transformers import pipeline\n",
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.decomposition import TruncatedSVD\n",
        "from nltk.tokenize import sent_tokenize\n",
        "from langdetect import detect"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NL_ZQn5RTAEE"
      },
      "outputs": [],
      "source": [
        "def generate_summary(url, max_length=150):\n",
        "    \"\"\"\n",
        "    Summarizes the transcript of a YouTube video.\n",
        "\n",
        "    This function takes a YouTube video URL and an optional max_length parameter as inputs.\n",
        "    It first retrieves the transcript of the YouTube video.\n",
        "    If the transcript is longer than 3000 words, it uses extractive summarization (e.g. LSA).\n",
        "    Otherwise, it uses abstractive summarization.\n",
        "\n",
        "    Parameters:\n",
        "    - url (str): The URL of the YouTube video.\n",
        "    - max_length (int, optional): The maximum length of the summary. Defaults to 150.\n",
        "\n",
        "    Returns:\n",
        "    - str: The summarized transcript.\n",
        "    \"\"\"\n",
        "    # max_length = int(request.args.get('max_length', 150))\n",
        "    video_id = url.split('=')[1]\n",
        "    # video_id = \"IitIl2C3Iy8\"\n",
        "    # max_length = max(int(max_length), 150)\n",
        "\n",
        "    try:\n",
        "        transcript_list, transcript, length = get_transcript(video_id)\n",
        "        max_length = max(int(max_length), 150)\n",
        "    except:\n",
        "        return \"No subtitles available for this video\", 404\n",
        "\n",
        "    # Extractive summarization using LSA or Frequency-based method\n",
        "    # if len(transcript.split()) > 3000:\n",
        "    #     summary = extractive_summarization(transcript)\n",
        "    # else:\n",
        "    #     summary = abstractive_summarization(transcript, max_length)\n",
        "\n",
        "\n",
        "    summary = textrank(transcript)\n",
        "\n",
        "    return transcript_list, summary, 200"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dQtuuL8GE_Al",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "17ed822a-7ae8-44d2-8bd2-55c9ee8d26f6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.10/dist-packages\n"
          ]
        }
      ],
      "source": [
        "import spacy\n",
        "import pytextrank\n",
        "\n",
        "\n",
        "def textrank(transcript):\n",
        "  nlp = spacy.load(\"en_core_web_lg\")\n",
        "  nlp.add_pipe(\"textrank\")\n",
        "  example_text = transcript\n",
        "  length = len(transcript.split(\".\"))\n",
        "  print('Original Document Size:', length)\n",
        "  doc = nlp(example_text)\n",
        "  summary = ''\n",
        "  limit_phrases = 2\n",
        "  limit_sentences = length // 3\n",
        "\n",
        "  print('SUmmary Document Size:', limit_sentences)\n",
        "\n",
        "\n",
        "\n",
        "  for sent in doc._.textrank.summary(limit_phrases=limit_phrases, limit_sentences=limit_sentences):\n",
        "    # print(sent)\n",
        "    summary = summary + str(sent)\n",
        "    # print('Summary Length:',len(sent))\n",
        "  return summary\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t-1XI_q8TDgo"
      },
      "outputs": [],
      "source": [
        "def is_transcript_english(transcript):\n",
        "    \"\"\"\n",
        "    Detect if the transcript is primarily in English.\n",
        "\n",
        "    :param transcript: The transcript text to be analyzed.\n",
        "    :return: True if the transcript is primarily in English, False otherwise.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        language = detect(transcript)\n",
        "        return language == 'en'\n",
        "\n",
        "    except Exception as e:\n",
        "        return False\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ItzvRubsTHja"
      },
      "outputs": [],
      "source": [
        "def get_transcript(video_id):\n",
        "    \"\"\"\n",
        "    Fetches and concatenates the transcript of a YouTube video.\n",
        "\n",
        "    Parameters:\n",
        "    video_id (str): The ID of the YouTube video.\n",
        "\n",
        "    Returns:\n",
        "    str: A string containing the concatenated transcript of the video.\n",
        "\n",
        "    Raises:\n",
        "    Exception: If there is an error in fetching the transcript.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        transcript_list = YouTubeTranscriptApi.get_transcript(video_id)\n",
        "        max_length = len(transcript_list)\n",
        "    except Exception as e:\n",
        "        raise e\n",
        "\n",
        "    transcript = ' '.join([d['text'] for d in transcript_list])\n",
        "    return transcript_list, transcript, max_length"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 227
        },
        "id": "AVA6u6-8Ta3u",
        "outputId": "7dc9ee94-8c41-4512-a345-2ae2038d4d80"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Document Size: 92\n",
            "SUmmary Document Size: 30\n",
            "Summary of the YouTube video:\n",
            "***************************************************\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Confident people celebrate the success\\nof others rather than feeling threatened.Confident people support\\nthose around them.I vividly remember standing\\non the warning track of the baseball field 45 minutes before game time, looking at the opposing manager\\nand his team wearing the wrong color uniform.Transcriber: Glenny Lapaix\\nReviewer:Vivian Lim When I was in high school, my mom asked me to order a pizza\\nfor the family on a Friday night.I looked up the number\\nin the phone book and promptly handed the phone\\nto my older brother to place the call.I was too shy to talk to a stranger.Fast-forward to college\\nat the University of Illinois, my first time away from my small town.I spent the first several weeks\\ncrying in my dorm room, too homesick to partake\\nin early freshman partying.The one frat party I did attend\\nwas so disappointing; I wanted to trade in my books,\\nabandon my major and head back home to my small town.The confident behaviors I needed\\nto pursue this dream were not yet available.And when I looked around\\nat the confident students walking around me on campus, heads held high, pursuing a dream\\nthat they had set out to achieve, I wanted that kind of confidence too.But my behaviors did not align\\nwith these confident attitudes.Crying in my dorm room,\\nshying away from social engagement, not showing up for class because I was worried\\nothers were smarter than me - these were not going to lead me\\nto achieve my goal.So all I knew was that I needed to change.Research tells us that in order\\nto get people to change, you need to not start with the attitudes, but with the behaviors\\nassociated with those attitudes.When people can see themselves\\nbehaving differently, they then begin to act differently.So the questions for me were, “Who am I?”“Who do I want to become?” and “How does this person\\nI want to become behave?”The answers were that I wanted\\na successful career, one that meant something,\\nallowed me to contribute.And for me, that was defined as a career\\nas a sports executive.In order to achieve this goal,\\nI needed to begin to act more confidently.And I did.Because 13 years later, I became\\nthe first female general manager of a Triple-A baseball team\\nin nearly 20 years.(Cheers) Thank you.(Applause)I also went on to host\\nthe “Leadership is Female” podcast, where I’ve interviewed\\nover 90 female executives in sports, an industry that’s over 80% male\\nat management level and above.And time after time,\\nthese women have told me that the number one skill they’ve improved in order to earn their spot\\nat the top of the sports industry is confidence.They, like me, did not possess\\nthis confidence necessary to increase their level\\nin their career from the get-go.They had to work on the behaviors\\nassociated with this attitude in order to propel their career forward.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "# Prompt the user to input the YouTube video URL and maximum length of the summary\n",
        "# url = input(\"Paste your YouTube video URL: \")\n",
        "# max_length = input(\"Enter maximum length of the summary (in sentences): \")\n",
        "\n",
        "url = \"https://www.youtube.com/watch?v=IitIl2C3Iy8\"\n",
        "max_length = 75\n",
        "\n",
        "# Call the function 'generate_summary' to generate the summary\n",
        "transcript_list, summary_paragraph, status = generate_summary(url, max_length)\n",
        "\n",
        "# Print a header for the summary\n",
        "print(\"Summary of the YouTube video:\\n***************************************************\\n\")\n",
        "\n",
        "# Display the summary paragraph\n",
        "summary_paragraph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JCVUHhlxdCVg",
        "outputId": "71d3dde8-2ed6-4b1f-9bf7-5ce174ed751e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'text': 'When I was in high school,', 'start': 15.445, 'duration': 1.302},\n",
              " {'text': 'my mom asked me to order a pizza\\nfor the family on a Friday night.',\n",
              "  'start': 16.747,\n",
              "  'duration': 3.57},\n",
              " {'text': 'I looked up the number\\nin the phone book',\n",
              "  'start': 20.751,\n",
              "  'duration': 1.868},\n",
              " {'text': 'and promptly handed the phone\\nto my older brother to place the call.',\n",
              "  'start': 22.619,\n",
              "  'duration': 3.203},\n",
              " {'text': 'I was too shy to talk to a stranger.',\n",
              "  'start': 25.889,\n",
              "  'duration': 2.67},\n",
              " {'text': 'Fast-forward to college\\nat the University of Illinois,',\n",
              "  'start': 28.959,\n",
              "  'duration': 2.636},\n",
              " {'text': 'my first time away from my small town.',\n",
              "  'start': 31.895,\n",
              "  'duration': 2.302},\n",
              " {'text': 'I spent the first several weeks\\ncrying in my dorm room,',\n",
              "  'start': 34.231,\n",
              "  'duration': 2.869},\n",
              " {'text': 'too homesick to partake\\nin early freshman partying.',\n",
              "  'start': 37.334,\n",
              "  'duration': 3.103},\n",
              " {'text': 'The one frat party I did attend\\nwas so disappointing;',\n",
              "  'start': 40.837,\n",
              "  'duration': 3.904},\n",
              " {'text': 'I wanted to trade in my books,\\nabandon my major',\n",
              "  'start': 44.741,\n",
              "  'duration': 2.403},\n",
              " {'text': 'and head back home to my small town.',\n",
              "  'start': 47.144,\n",
              "  'duration': 1.802},\n",
              " {'text': 'The confident behaviors I needed\\nto pursue this dream',\n",
              "  'start': 50.08,\n",
              "  'duration': 3.103},\n",
              " {'text': 'were not yet available.', 'start': 53.283, 'duration': 1.368},\n",
              " {'text': 'And when I looked around\\nat the confident students',\n",
              "  'start': 54.718,\n",
              "  'duration': 2.636},\n",
              " {'text': 'walking around me on campus,', 'start': 57.354, 'duration': 1.835},\n",
              " {'text': 'heads held high, pursuing a dream\\nthat they had set out to achieve,',\n",
              "  'start': 59.323,\n",
              "  'duration': 4.871},\n",
              " {'text': 'I wanted that kind of confidence too.',\n",
              "  'start': 64.294,\n",
              "  'duration': 2.236},\n",
              " {'text': 'But my behaviors did not align\\nwith these confident attitudes.',\n",
              "  'start': 66.797,\n",
              "  'duration': 3.804},\n",
              " {'text': 'Crying in my dorm room,\\nshying away from social engagement,',\n",
              "  'start': 70.834,\n",
              "  'duration': 3.237},\n",
              " {'text': 'not showing up for class', 'start': 74.204, 'duration': 1.301},\n",
              " {'text': 'because I was worried\\nothers were smarter than me -',\n",
              "  'start': 75.505,\n",
              "  'duration': 2.403},\n",
              " {'text': 'these were not going to lead me\\nto achieve my goal.',\n",
              "  'start': 77.975,\n",
              "  'duration': 2.636},\n",
              " {'text': 'So all I knew was that I needed to change.',\n",
              "  'start': 80.644,\n",
              "  'duration': 2.736},\n",
              " {'text': 'Research tells us that in order\\nto get people to change,',\n",
              "  'start': 83.981,\n",
              "  'duration': 2.936},\n",
              " {'text': 'you need to not start with the attitudes,',\n",
              "  'start': 87.017,\n",
              "  'duration': 2.803},\n",
              " {'text': 'but with the behaviors\\nassociated with those attitudes.',\n",
              "  'start': 89.82,\n",
              "  'duration': 3.57},\n",
              " {'text': 'When people can see themselves\\nbehaving differently,',\n",
              "  'start': 93.557,\n",
              "  'duration': 3.036},\n",
              " {'text': 'they then begin to act differently.',\n",
              "  'start': 96.693,\n",
              "  'duration': 3.07},\n",
              " {'text': 'So the questions for me were,',\n",
              "  'start': 100.364,\n",
              "  'duration': 1.534},\n",
              " {'text': '“Who am I?”', 'start': 102.399, 'duration': 1.001},\n",
              " {'text': '“Who do I want to become?”', 'start': 103.9, 'duration': 1.469},\n",
              " {'text': 'and “How does this person\\nI want to become behave?”',\n",
              "  'start': 105.869,\n",
              "  'duration': 3.137},\n",
              " {'text': 'The answers were that I wanted\\na successful career,',\n",
              "  'start': 109.673,\n",
              "  'duration': 2.669},\n",
              " {'text': 'one that meant something,\\nallowed me to contribute.',\n",
              "  'start': 112.342,\n",
              "  'duration': 3.404},\n",
              " {'text': 'And for me, that was defined as a career\\nas a sports executive.',\n",
              "  'start': 115.746,\n",
              "  'duration': 3.837},\n",
              " {'text': 'In order to achieve this goal,\\nI needed to begin to act more confidently.',\n",
              "  'start': 120.083,\n",
              "  'duration': 5.372},\n",
              " {'text': 'And I did.', 'start': 126.156, 'duration': 1.001},\n",
              " {'text': 'Because 13 years later, I became\\nthe first female general manager',\n",
              "  'start': 127.424,\n",
              "  'duration': 3.87},\n",
              " {'text': 'of a Triple-A baseball team\\nin nearly 20 years.',\n",
              "  'start': 131.361,\n",
              "  'duration': 3.57},\n",
              " {'text': '(Cheers)', 'start': 135.532, 'duration': 1.001},\n",
              " {'text': 'Thank you.', 'start': 136.533, 'duration': 1.001},\n",
              " {'text': '(Applause)', 'start': 137.534, 'duration': 1.135},\n",
              " {'text': 'I also went on to host\\nthe “Leadership is Female” podcast,',\n",
              "  'start': 141.405,\n",
              "  'duration': 3.169},\n",
              " {'text': 'where I’ve interviewed\\nover 90 female executives in sports,',\n",
              "  'start': 144.574,\n",
              "  'duration': 4.071},\n",
              " {'text': 'an industry that’s over 80% male\\nat management level and above.',\n",
              "  'start': 148.712,\n",
              "  'duration': 4.338},\n",
              " {'text': 'And time after time,\\nthese women have told me',\n",
              "  'start': 153.25,\n",
              "  'duration': 2.502},\n",
              " {'text': 'that the number one skill they’ve improved',\n",
              "  'start': 155.819,\n",
              "  'duration': 2.536},\n",
              " {'text': 'in order to earn their spot\\nat the top of the sports industry',\n",
              "  'start': 158.355,\n",
              "  'duration': 3.503},\n",
              " {'text': 'is confidence.', 'start': 162.092, 'duration': 1.168},\n",
              " {'text': 'They, like me, did not possess\\nthis confidence necessary',\n",
              "  'start': 163.894,\n",
              "  'duration': 4.771},\n",
              " {'text': 'to increase their level\\nin their career from the get-go.',\n",
              "  'start': 168.899,\n",
              "  'duration': 3.603},\n",
              " {'text': 'They had to work on the behaviors\\nassociated with this attitude',\n",
              "  'start': 172.969,\n",
              "  'duration': 3.904},\n",
              " {'text': 'in order to propel their career forward.',\n",
              "  'start': 176.873,\n",
              "  'duration': 2.57},\n",
              " {'text': 'I vividly remember standing\\non the warning track of the baseball field',\n",
              "  'start': 244.674,\n",
              "  'duration': 3.804},\n",
              " {'text': '45 minutes before game time,', 'start': 248.645, 'duration': 1.969},\n",
              " {'text': 'looking at the opposing manager\\nand his team wearing',\n",
              "  'start': 250.881,\n",
              "  'duration': 2.769},\n",
              " {'text': 'the wrong color uniform.', 'start': 253.65, 'duration': 1.768},\n",
              " {'text': 'Confident people celebrate the success\\nof others rather than feeling threatened.',\n",
              "  'start': 406.703,\n",
              "  'duration': 5.939},\n",
              " {'text': 'Confident people support\\nthose around them.',\n",
              "  'start': 462.025,\n",
              "  'duration': 3.537},\n",
              " {'text': 'Thank you.', 'start': 602.365, 'duration': 1.001}]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "import json\n",
        "\n",
        "# Define a function to match text in a paragraph with text in a list of JSON objects\n",
        "def match_text_in_json(paragraph, json_list):\n",
        "    matched_list = []\n",
        "    # Iterate over each JSON object in the list\n",
        "    for obj in json_list:\n",
        "        # Check if the text of the JSON object (case-insensitive) is present in the paragraph\n",
        "        if obj['text'].lower() in paragraph.lower():\n",
        "            # If a match is found, append the JSON object to the matched list\n",
        "            matched_list.append(obj)\n",
        "    return matched_list\n",
        "\n",
        "# SUmmary paragraph paragraph to search for matches\n",
        "paragraph = summary_paragraph\n",
        "\n",
        "# transcript  list of JSON objects\n",
        "json_list = transcript_list\n",
        "\n",
        "# Call the function to find JSON objects that match text in the paragraph\n",
        "matched_json = match_text_in_json(paragraph, json_list)\n",
        "\n",
        "# Print the matched JSON objects\n",
        "matched_json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e1hALeyCiq2W",
        "outputId": "61ab6943-cec6-4d55-8166-a81736ab151f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'start': 15.445, 'duration': 33.501},\n",
              " {'start': 50.08, 'duration': 88.589},\n",
              " {'start': 141.405, 'duration': 38.03799999999999},\n",
              " {'start': 244.674, 'duration': 10.744},\n",
              " {'start': 406.703, 'duration': 5.939},\n",
              " {'start': 462.025, 'duration': 3.537},\n",
              " {'start': 602.365, 'duration': 1.001}]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "def merge_dicts(input_list):\n",
        "\n",
        "    '''\n",
        "    This function, merge_dicts, takes a list of dictionaries input_list as input, where each dictionary represents\n",
        "    a segment with keys 'start' and 'duration'. The function merges overlapping segments within the list, ensuring\n",
        "    that no two segments overlap in time.\n",
        "    '''\n",
        "    output_list = []\n",
        "    n = len(input_list)\n",
        "    i = 0\n",
        "\n",
        "    while i < n:\n",
        "        current_segment = input_list[i]\n",
        "        j = i + 1\n",
        "\n",
        "        while j < n and current_segment['start'] + current_segment['duration'] + 1 >= input_list[j]['start']:\n",
        "            # Merge overlapping segments\n",
        "            current_segment['duration'] = input_list[j]['start'] - current_segment['start'] + input_list[j]['duration']\n",
        "            j += 1\n",
        "\n",
        "        output_list.append({'start': current_segment['start'], 'duration': current_segment['duration']})\n",
        "        i = j\n",
        "\n",
        "    return output_list\n",
        "    return merged_list\n",
        "\n",
        "# Sample input\n",
        "input_list = matched_json\n",
        "\n",
        "# Call the function and print the output\n",
        "merged_matched_json = merge_dicts(input_list)\n",
        "#Print the merged output list\n",
        "merged_matched_json\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xUzq0uHjTzGe",
        "outputId": "aafb38d1-ee3a-4eac-9d80-1a0afabbc29b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/original_video.mp4'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "from pytube import YouTube\n",
        "\n",
        "# Create a YouTube object by passing the video URL\n",
        "yt = YouTube(url)\n",
        "\n",
        "# Filter streams to select only progressive MP4 streams and order them by resolution\n",
        "selected_stream = yt.streams.filter(progressive=True, file_extension='mp4').order_by('resolution').first()\n",
        "\n",
        "# Download the selected stream with the lowest resolution and save it as 'original_video.mp4'\n",
        "selected_stream.download(filename='original_video.mp4')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eAu138ZgT24X",
        "outputId": "6bcced44-4cf0-4ac3-a3d8-b2dbf5d049e6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<moviepy.video.io.VideoFileClip.VideoFileClip object at 0x781eb31d2c20>\n",
            "Moviepy - Building video final_video.mp4.\n",
            "MoviePy - Writing audio in final_videoTEMP_MPY_wvf_snd.mp3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MoviePy - Done.\n",
            "Moviepy - Writing video final_video.mp4\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Moviepy - Done !\n",
            "Moviepy - video ready final_video.mp4\n"
          ]
        }
      ],
      "source": [
        "from moviepy.editor import VideoFileClip, concatenate_videoclips\n",
        "\n",
        "# Load the original video\n",
        "original_video = VideoFileClip(\"original_video.mp4\")\n",
        "\n",
        "# List of start positions and durations\n",
        "video_segments = merged_matched_json\n",
        "\n",
        "# List to store cut video clips\n",
        "cut_clips = []\n",
        "\n",
        "# Cut the video based on segments\n",
        "for segment in video_segments:\n",
        "    start_time = segment[\"start\"]\n",
        "    duration = segment[\"duration\"]\n",
        "    end_time = start_time + duration\n",
        "\n",
        "    # Cut the segment from the original video\n",
        "    cut_clip = original_video.subclip(start_time, end_time)\n",
        "    cut_clips.append(cut_clip)\n",
        "\n",
        "print(cut_clip)\n",
        "# Concatenate all the cut clips\n",
        "final_video = concatenate_videoclips(cut_clips)\n",
        "\n",
        "\n",
        "# Export the final video\n",
        "final_video.write_videofile(\"final_video.mp4\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Jre60pnUont",
        "outputId": "4382cc24-f0c3-46dd-ba7f-a2270349abc0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Video object>"
            ],
            "text/html": [
              "<video src=\"final_video.mp4\" controls  >\n",
              "      Your browser does not support the <code>video</code> element.\n",
              "    </video>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "from IPython.display import Video\n",
        "\n",
        "# final_video.mp4 is in the current directory\n",
        "video_path = \"final_video.mp4\"\n",
        "\n",
        "# Display the video\n",
        "Video(video_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zEH-3gTx31U5"
      },
      "source": [
        "**Evaluation**\n",
        "---\n",
        "\n",
        "----\n",
        "In order to evaluate the effectiveness of the summarization model, I conducted a test with Ms. Boddu Kavya, a MSIT student at the University of Cincinnati. Ms. Kavya was provided with an original video approximately 11 minutes long titled **\"*Six behaviors to increase your confidence | Emily Jaenson | TEDxReno*\"**. Subsequently, she was shown the summary video of 3 minutes long generated by the project.\n",
        "\n",
        "Ms. Kavya provided positive feedback on the summarization features, stating that most of the significant information from the original video was covered in the summary video. She scored the model with a rating of 90 out of 100, indicating a high level of satisfaction with the summarization output. Additionally, she mentioned that by using the model's output on other videos, she was able to save a significant amount of time by referring to the summary videos.\n",
        "\n",
        "However, Ms. Kavya also noted that while the summary videos were helpful for revision purposes, they may not be solely dependable for study purposes, as some important information may be left out by the model. Nonetheless, she expressed confidence in using the model for revision and quick reference purposes.\n",
        "\n",
        "Overall, the evaluation results indicate that the summarization model effectively condenses lengthy videos into concise summaries, capturing the essential information and providing users with a valuable tool for efficient content consumption. Further refinements and enhancements to the model could potentially improve its performance and utility for a wider range of applications.\n",
        "\n",
        "----\n",
        "In order to ensure the authenticity of the evalution / feedback section, here are the contact details of the evaluator:\n",
        "\n",
        "Evaluator Information:\n",
        "\n",
        "- Name: Boddu Kavya\n",
        "- Email: bodduka@mail.uc.edu"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WQQa9vXj1q-B"
      },
      "source": [
        "**Results and Conclusions**\n",
        "---\n",
        "\n",
        "---\n",
        "The project successfully achieved its goal of generating short YouTube videos using the MoviePy library based on the filtered transcript list. By extracting timestamps from the filtered transcript list, we were able to accurately segment the original video and concatenate these segments to create a concise summary video.\n",
        "\n",
        "The summarization process involved filtering the transcript list to include only sentences present in the summary paragraph. This ensured that the generated summary video captured the most important aspects of the original content. The timestamps extracted from the filtered transcript list served as the basis for cutting and concatenating video segments, resulting in a coherent summary video.\n",
        "\n",
        "Through this approach, we effectively condensed lengthy YouTube videos into shorter, more digestible summaries, making it easier for viewers to grasp the key points without having to watch the entire video. This has significant implications for content creators, educators, and consumers alike, as it allows for more efficient consumption and dissemination of video content.\n",
        "\n",
        "In conclusion, the project demonstrates the feasibility and effectiveness of using automated summarization techniques to generate concise video summaries. By leveraging tools such as the MoviePy library and filtering techniques based on transcript analysis, we can streamline the process of summarizing video content and enhance its accessibility and usability for a wide range of audiences. This project lays the foundation for future research and development in the field of video summarization, paving the way for more advanced and sophisticated approaches to content summarization and analysis."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BKHkXKlUmNhr"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}